\section{A PDE optimal control problem}
A physical object $\Omega = (0, 1)$ is to be heated or cooled to some desired temperature profile $y_d \in L^2 (\Omega)$. At the boundaries the (relative) temperature is $0$. 
We can control a heat source $u$ and there is some cost $\alpha \in (0, \infty)$ associated with heating/cooling the object.
Our problem is then to minimize the discrepancy between the desired profile and the temperature profile of the object, while simultaneously minimizing the cost of the heating/cooling.
Our problem then becomes
\begin{equation}
    \label{eq:OCP}
    \min_{y, u} \frac{1}{2} \int_0^1 \lvert y - y_d \rvert^2 dx + \frac{\alpha}{2}\int_0^1u^2 dxn
    \quad s.t. \quad \begin{cases}
       -\Delta y = u \\
       y(0) = y(1) = 0
    \end{cases} 
    \quad \text{in the weak sense.}
\end{equation}
We approximate this as 
\begin{equation}
    \label{eq:OCP_FE}
    \min_{u_h, y_h \in V_h} \frac{1}{2} \lVert y_h - \bar{y_d} \rVert_ {L^2(\Omega)}^2 + \frac{\alpha}{2} \lVert u_h \rVert_{L^2(\Omega)}^2
    \quad \text{s.t.} \quad a(y_h, v) = \langle u_h, v \rangle_{L^2(\Omega)} \forall v \in V_h,
\end{equation}
where $\bar{y}_d$ is the interpolation of $y_d$ onto $X_h^2$, $V_h = X_h^2 \cap H_0^1 (\Omega)$ and $a(u, v) = \int_0^1 u_x v_x dx$.
The optimal control is then $u_h$, and the optimal state is $y_h$.
\subsection{TODO: utledning}
To find a solution we interpret this as a minimization problem for the unknown coefficients $\mathbf{u} = \{u_1, \dots, u_{2N-1} \}$, $\mathbf{y} = \{y_1, \dots, y_{2N-1} \}$ as
\begin{equation}
    \label{eq:OCP_coeff}
    \min_{\mathbf{y,u} \in \mathds{R}^{2N-1}} G(\mathbf{y, u}) \quad \text{s.t.} \quad B\mathbf{y} = F\mathbf{u}.
\end{equation}
For $F$ and $B$ we use each side of the constraint from (\ref{eq:OCP_FE}). If the constraint holds for some $\varphi_i$ it holds for all $v_h\in V_H$ which gives us the forms,
$$a(y_h, \varphi_j) = \int_0^1 \left( \sum_{i=1}^{2N-1} y_i \varphi_i' \varphi_j' \right)dx =\sum_{i=1}^{2N-1} y_i\int_0^1 \left( \varphi_i' \varphi_j' \right)dx,$$
which can be written for all $\varphi$'s as $B\mathbf{y}$, where $B_{i,j} = \int_0^1 \varphi_i' \varphi_j'dx$,  $i,j = 1, \dots, 2N-1$, and  
$$\langle u_h, \varphi_j \rangle_{L^2(\Omega)} = \int_0^1 \sum_{i=1}^{2N-1} u_i \varphi_i \varphi_j dx =\sum_{i=1}^{2N-1} u_i \int_0^1  \varphi_i \varphi_j dx,$$
which can be written for all $\varphi$'s as $F\mathbf{u}$, where $F_{i,j}=\int_0^1  \varphi_i \varphi_j dx$, $i,j = 1, \dots, 2N-1$.
One can see that $B$ is the same as the stiffness matrix.

We find $G(\mathbf{y, u})$ by rewriting the objective function of (\ref{eq:OCP_FE}).
Since the desired profile is an interpolation, we know that $\bar{y}_d = \sum_{i=0}^{2N}d_i\varphi_i$, where $\mathbf{d}$ are coefficients, giving the form
\begin{align*}
    G(\mathbf{y, u}) &= \frac{1}{2}\langle y_h - \bar{y}_d, y_h - \bar{y}_d \rangle_{L^2{(\Omega)}} + \frac{\alpha}{2} \langle u_h, u_h \rangle_{L^2(\Omega)} \\
   &= \frac{1}{2}\langle y_h , y_h \rangle_{L^2{(\Omega)}} +  \frac{1}{2}\langle \bar{y}_d ,\bar{y}_d  \rangle_{L^2{(\Omega)}}
   - \langle y_h, \bar{y}_d \rangle_{L^2{(\Omega)}} + \frac{\alpha}{2} \langle u_h, u_h \rangle_{L^2(\Omega)} \\
     &= \frac{1}{2}\int_0^1\left( \sum_{i=1}^{2N-1}y_i \varphi_i \right)^2dx  + \frac{1}{2}\int_0^1\left( \sum_{i=0}^{2N}d_i \varphi_i \right)^2dx \\
     &- \int_0^1\left( \sum_{i=1}^{2N-1}y_i \varphi_i \right) \left(d_0 \varphi_0 + \sum_{i=1}^{2N-1} d_i \varphi_i + d_{2N} \varphi_{2N} \right)dx + 
     \frac{\alpha}{2}\int_0^1\left(\sum_{i=1}^{2N-1} u_i \varphi_i  \right)^2dx \\    
     &= \frac{1}{2}\sum_{i=1}^{2N-1}\sum_{j=1}^{2N-1} y_i y_j \int_0^1 \varphi_i \varphi_j dx + \frac{1}{2}\sum_{i=0}^{2N}\sum_{j=0}^{2N} d_i d_j \int_0^1 \varphi_i \varphi_j dx \\
    &- \sum_{i=1}^{2N-1} \sum_{j=0}^{2N} y_i d_i \int_0^1 \varphi_i \varphi_j dx +  \frac{\alpha}{2}\sum_{i=1}^{2N-1}\sum_{j=1}^{2N-1} u_i u_j \int_0^1\varphi_i \varphi_j dx.
\end{align*}
We can rewrite this in the form
$$
G(\mathbf{y, u}) = \frac{1}{2}\mathbf{y}^T F \mathbf{y} + \frac{1}{2}\mathbf{d}^T\Tilde{F} \mathbf{d} - \mathbf{y}^T\hat{F}\mathbf{d} + \frac{\alpha}{2}\mathbf{u}^T F \mathbf{u},
$$
where $\Tilde{F} \in \mathds{R}^{(2N+1) \times (2N+1)}$ has the same elements as $F$, but $i, j = 0, \dots, 2N$, 
and $\hat{F} \in \mathds{R}^{(2N-1) \times (2N+1)}$ is the same as $\Tilde{F}$ but with the first and last row removed.  

To find a solution to equation (\ref{eq:OCP_coeff}) we use Lagrange multipliers and the Lagrangian
\begin{align}
    \label{eq:OCP_lagrangian}
    \mathcal{L}(\mathbf{y, u, \lambda}) &= G(\mathbf{y, u}) - \mathbf{\lambda}^T \left( B\mathbf{y} - F\mathbf{u} \right) \\
    &= \frac{1}{2}\mathbf{y}^T F \mathbf{y} + \frac{1}{2}\mathbf{d}^T\Tilde{F} \mathbf{d} - \mathbf{y}^T\hat{F}\mathbf{d} + \frac{\alpha}{2}\mathbf{u}^T F \mathbf{u}  - \mathbf{\lambda}^T \left( B\mathbf{y} - F\mathbf{u} \right) ,
\end{align}
where $\mathbf{\lambda} \in \mathds{R}^{2N-1}$ is the vector of Lagrange multipliers.
The solution is found by solving
\begin{align}
    \label{eq:gradients}
    \nabla_{\mathbf{y}}\mathcal{L} = 0 \\
    \nabla_{\mathbf{u}}\mathcal{L} = 0 \\
    \nabla_{\mathbf{\mathbf{\lambda}}}\mathcal{L} = 0
\end{align}
for $\mathbf{y}$ and $\mathbf{u}$.
Calculating the gradients, and exploiting the symmetry of \( F \) and \( B \)
yields the system
\begin{align}
  F \mathbf{y}- \hat{F}\mathbf{d} - B\mathbf{\lambda} &= 0 \\
  \alpha F \mathbf{u}+ F\mathbf{\lambda} &= 0 \\
  -B \mathbf{y} + F \mathbf{y} &= 0
\end{align}

\begin{lemma}
    $F$ is invertible.    
\end{lemma}
\begin{proof}
    \label{lemma:F_invertible}
    The basis functions $\varphi_i$ are linearly independent, since they are Lagrange nodal polynomials and our nodes are unique.
    Since $F_{i,j} = \int_0^1 \varphi_i \varphi_j dx = \langle \varphi_i, \varphi_j \rangle_{L^2(\Omega)}$,
    $F$ is a Gram-matrix corresponding to the vector space of our basis functions.
    Combining these results gives us that $F$ is positive definite and therefore invertible.
\end{proof}

\begin{lemma}
    \label{lemma:B_pos_def}
    $B$ is positive definite.
\end{lemma}
\begin{proof}
    Let $\mathbf{z} \in \mathds{R}^{(2N-1)}$, then 
    $$\mathbf{z}^T B \mathbf{z} = \sum_{i=1}^{2N-1}\sum_{j=1}^{2N-1} z_i B_{i,j}z_j =\sum_{i=1}^{2N-1}\sum_{j=1}^{2N-1}a(v_i \varphi_i, v_j\varphi_j) >0 .$$
\end{proof}

\begin{lemma}
    $BF^{-1}B$ is positive definite.
\end{lemma}
\begin{proof}
    $F^{-1}$ is positive definite since it is the inverse of a positive definite matrix and $\ker(B) = \{0\}$ since $B$ is positive definite, by lemma (\ref{lemma:B_pos_def}).
    
    Let $\mathbf{z} \in \mathds{R}^{2N-1}$,
    $$\mathbf{z}^T BF^{-1}B \mathbf{z} = (B\mathbf{z})^T F^{-1}(B\mathbf{z}) > 0.$$
\end{proof}
Since $F$ is invertible, by lemma (\ref{lemma:F_invertible}), we see that $\alpha \mathbf{u}= -\mathbf{\lambda}$. 
This gives the system
\begin{align}
    \label{eq:lagrange_conditions}
     F \mathbf{y} + \alpha B \mathbf{u} &= \hat{F}\mathbf{d} \\
    -B \mathbf{y} + F \mathbf{u} &= \mathbf{0}.
\end{align}
An explicit solution can be found by seeing that $\mathbf{u}=F^{-1}B \mathbf{y}$, and getting
$$ F\mathbf{y} + \alpha B F^{-1}B \mathbf{y} = \hat{F}\mathbf{d},$$
which gives the solutions
\begin{align*}
    \mathbf{y} &= \left[F + \alpha B F^{-1}B \right]^{-1} \hat{F}\mathbf{d} \\
    \mathbf{u} &= F^{-1} B \left[F + \alpha B F^{-1}B \right]^{-1} \hat{F}\mathbf{d},
\end{align*}
where $\left[F + \alpha B F^{-1}B \right]^{-1}$ exists since $\alpha > 0$ and it is therefore the inverse of the sum of positive definite matrices.
The system can also be written in block matrix form as
$$
\begin{bmatrix}
   F & \alpha B \\
   -B & F \\
\end{bmatrix}
\begin{bmatrix}
    \mathbf{y} \\
    \mathbf{u}
\end{bmatrix}
= 
\begin{bmatrix} \hat{F}\mathbf{d} \\
    \mathbf{0}
\end{bmatrix}.
$$
This system has sparse sub-blocks, which can solved
effieciently by sparse solver.

TODO: mer om hvordan den spesifikke implementasjonen??? Skal vi ha med explisitte uttrykk for $\mathbf{y}$ og $\mathbf{u}$??

\subsection{Example temperature profiles}
We wish to test our implementation for some different desired temperature profiles,
\begin{align}
    \label{eq:desired_profiles}
    y_d &= \frac{1}{2}x(1-x), \\
    y_d &= 1, \\
    y_d &= \begin{cases}
        1 \quad \text{for} \quad x \in \left[ \frac{1}{4}, \frac{3}{4}\right] \\
        0 \quad \text{else}.
    \end{cases}
\end{align}

TODO: comment on \( \alpha \) and the three different desired temp. profiles.
We see that for a high cost, figure (\ref{fig:0}), the discrepancy between the optimal state and the desired profile is large, while the optimal state is ???.
I.e. the optimal control becomes minimized at the expense of the discrepancy.
In contrast, for low cost, figure (\ref{fig:2}), the discrepancy between the optimal state and the desired profile is almost non-existent and the optimal state is extreme??.
For a typical cost figure (\ref{eq:1}), we see that there is some discrepancy from the desired profile, but the optimal control is still smooth ???.
This is what we would expect from the original problem. For typical costs both the discrepancy and the heating/cooling are somewhat minimized, while either one of them are minimized for low/high costs.

Since our optimal state and optimal control are in $H_0^1$, but our desired profile not guaranteed to be, we might get interesting results if we choose a desired profile not in $H_0^1$.
This is the case for both the second and third desired profiles in (\ref{eq:desired_profiles}).
We see that for both high and normal costs, both the optimal control and state are smooth.
In contrast, for low costs, figure (\ref{fig:2}), the optimal control is rather extreme at the boundaries and for discontinuities. This happens becasue????
This is not the case for the first desired temperature profile, since it is an element of $H_0^1$.

TODO: more plots?


\begin{figure}[!h]
  \centering
  \includegraphics[width=\textwidth]{Images/plots/task2_fig_0.pdf}
  \caption{Plotting of an optimized control problem for different desired temperature profiles. The upper row contains plots of different desired temperature profiles and their corresponding optimal state.
  The lower row contains plots of the optimal sate for the corresponding problem. The cost, $\alpha$, is here set to a low value.}
  \label{fig:0}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[width=\textwidth]{Images/plots/task2_fig_1.pdf}
  \caption{Plotting of an optimized control problem for different desired temperature profiles. The upper row contains plots of different desired temperature profiles and their corresponding optimal state.
  The lower row contains plots of the optimal sate for the corresponding problem. The cost, $\alpha$, is here set to a standard value.}
  \label{fig:1}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[width=\textwidth]{Images/plots/task2_fig_2.pdf}
  \caption{Plotting of an optimized control problem for different desired temperature profiles. The upper row contains plots of different desired temperature profiles and their corresponding optimal state.
  The lower row contains plots of the optimal sate for the corresponding problem. The cost, $\alpha$, is here set to a high value.}
  \label{fig:2}
\end{figure}


